# Response to Blumenstock

# Don't Forget People in the use of big data for development Nature: Sept. 2018

Lydia Troup
January 27

Blumenstock believes "designing data-enabled applications that work in the real world will require a slower approach that pays much more attention to the people behind the numbers," meaning effective data science must work slowly to ensure people are protected.
This claim is supported by the potential applications of existing data science and algorithms. Algorithms commonly used for big tech companies could be repurposed to help those in need; instead of matching ads to the consumer, they could match resorces to those in need.
It is important that data sciences work carefully, because there are a variety of potential problems with this method. There are unexpected outcomes, drawn from lack of knowledge in those targeted, furthering the divide between the rich/empowered and the poor. Additionally, outcomes from digital data collection methods are inconsistent. For example, the correlation between wealth and quantity of international phonecalls differs throughout Africa. Algorithms based of digital data can be biased, as one must have a digital presence via smartphones or Facebook to produce data. Thus those most in need of development aid are often excluded. Lastly, digital data collection is unregulated by government agencies and generally collected and owned by private companies.
Blumenstock believes it is important to address the pitfalls. He states digital data should accompany the conventional data in order to ensure all individuals are included. Contextualization is important aswell, most digital data is made by and for first-world countries, meaning it's outcomes cannot always be applied to developing countries. To counteract this the data collected in developing countries has to be contextualized using the environment it was collected in.
